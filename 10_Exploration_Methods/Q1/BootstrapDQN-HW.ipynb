{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":11924.390442,"end_time":"2025-06-29T01:21:59.841554","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-28T22:03:15.451112","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"7dc8119f","cell_type":"markdown","source":"# 📋 **Student Information**","metadata":{"papermill":{"duration":0.010621,"end_time":"2025-06-28T22:03:19.703255","exception":false,"start_time":"2025-06-28T22:03:19.692634","status":"completed"},"tags":[]}},{"id":"5652e47a","cell_type":"markdown","source":"*Complete the required fields below with your personal and W&B account details.*","metadata":{"papermill":{"duration":0.009116,"end_time":"2025-06-28T22:03:19.722209","exception":false,"start_time":"2025-06-28T22:03:19.713093","status":"completed"},"tags":[]}},{"id":"c2d11728","cell_type":"code","source":"FIRST_NAME = \"Danial\" # replace with your first name\nLAST_NAME = \"Parnian\" # replace with your last name\nSTUDENT_ID = 401110307 # replace with your student id\nWANDB_ID = \"danielparnian\" # replace with your wandb username\nPROJECT_NAME = f\"{FIRST_NAME}-{LAST_NAME}-DQN-EXPLORE-HW\"\nprint(f\"Project name: {PROJECT_NAME}\")","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:08:32.843153Z","iopub.execute_input":"2025-06-29T07:08:32.843652Z","iopub.status.idle":"2025-06-29T07:08:32.851590Z","shell.execute_reply.started":"2025-06-29T07:08:32.843625Z","shell.execute_reply":"2025-06-29T07:08:32.850778Z"},"papermill":{"duration":0.018483,"end_time":"2025-06-28T22:03:19.749863","exception":false,"start_time":"2025-06-28T22:03:19.731380","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Project name: Danial-Parnian-DQN-EXPLORE-HW\n","output_type":"stream"}],"execution_count":1},{"id":"e7bcb56b","cell_type":"code","source":"print(f\"Check my results at https://wandb.ai/{WANDB_ID}/{PROJECT_NAME}\")","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:08:32.852742Z","iopub.execute_input":"2025-06-29T07:08:32.852986Z","iopub.status.idle":"2025-06-29T07:08:32.864538Z","shell.execute_reply.started":"2025-06-29T07:08:32.852970Z","shell.execute_reply":"2025-06-29T07:08:32.863699Z"},"papermill":{"duration":0.015796,"end_time":"2025-06-28T22:03:19.775258","exception":false,"start_time":"2025-06-28T22:03:19.759462","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Check my results at https://wandb.ai/danielparnian/Danial-Parnian-DQN-EXPLORE-HW\n","output_type":"stream"}],"execution_count":2},{"id":"100a81dd","cell_type":"code","source":"# Set DEBUG to True if you are still implementing the code and debugging\n# and don't want to make your wandb dashboard messy.\n# set DEBUG to False if you are almost done with the implementation\n# and want check performance and compare hyperparameters and models\nDEBUG = False","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:08:32.865312Z","iopub.execute_input":"2025-06-29T07:08:32.865578Z","iopub.status.idle":"2025-06-29T07:08:32.876193Z","shell.execute_reply.started":"2025-06-29T07:08:32.865556Z","shell.execute_reply":"2025-06-29T07:08:32.875536Z"},"papermill":{"duration":0.01453,"end_time":"2025-06-28T22:03:19.799448","exception":false,"start_time":"2025-06-28T22:03:19.784918","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"0becb4fb","cell_type":"markdown","source":"# 📘 Guidelines\n\n> ⚠️ **Please read this section carefully before proceeding.**","metadata":{"papermill":{"duration":0.00925,"end_time":"2025-06-28T22:03:19.825324","exception":false,"start_time":"2025-06-28T22:03:19.816074","status":"completed"},"tags":[]}},{"id":"ab1feadd","cell_type":"markdown","source":"### 🔧 Install Dependencies","metadata":{"papermill":{"duration":0.009193,"end_time":"2025-06-28T22:03:19.843966","exception":false,"start_time":"2025-06-28T22:03:19.834773","status":"completed"},"tags":[]}},{"id":"ad0cdef2","cell_type":"code","source":"!apt install build-essential python3-dev\n!git clone https://github.com/DeepRLCourse/Homework-10.git\n%pip install swig\n%pip install \"Homework-10/BootstrapDQN\"","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:08:32.877868Z","iopub.execute_input":"2025-06-29T07:08:32.878370Z","iopub.status.idle":"2025-06-29T07:10:58.332929Z","shell.execute_reply.started":"2025-06-29T07:08:32.878351Z","shell.execute_reply":"2025-06-29T07:10:58.332156Z"},"papermill":{"duration":148.53884,"end_time":"2025-06-28T22:05:48.392148","exception":false,"start_time":"2025-06-28T22:03:19.853308","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nbuild-essential is already the newest version (12.9ubuntu3).\npython3-dev is already the newest version (3.10.6-1~22.04.1).\npython3-dev set to manually installed.\n0 upgraded, 0 newly installed, 0 to remove and 87 not upgraded.\nCloning into 'Homework-10'...\nremote: Enumerating objects: 111, done.\u001b[K\nremote: Counting objects: 100% (111/111), done.\u001b[K\nremote: Compressing objects: 100% (67/67), done.\u001b[K\nremote: Total 111 (delta 37), reused 108 (delta 34), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (111/111), 1.14 MiB | 8.27 MiB/s, done.\nResolving deltas: 100% (37/37), done.\nCollecting swig\n  Downloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\nDownloading swig-4.3.1-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: swig\nSuccessfully installed swig-4.3.1\nNote: you may need to restart the kernel to use updated packages.\nProcessing ./Homework-10/BootstrapDQN\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: ale-py<=0.11.0,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (0.10.2)\nCollecting dotenv>=0.9.9 (from main==0.1.0)\n  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\nCollecting gymnasium>=1.1.1 (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0)\n  Downloading gymnasium-1.2.0-py3-none-any.whl.metadata (9.9 kB)\nCollecting ipykernel>=6.29.5 (from main==0.1.0)\n  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: nbformat>=5.10.4 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (5.10.4)\nRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (1.26.4)\nCollecting pip>=25.0.1 (from main==0.1.0)\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: swig>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (4.3.1)\nRequirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (2.6.0+cu124)\nRequirement already satisfied: wandb>=0.19.9 in /usr/local/lib/python3.11/dist-packages (from main==0.1.0) (0.19.9)\nCollecting python-dotenv (from dotenv>=0.9.9->main==0.1.0)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (3.1.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (4.13.2)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.1.1->gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (0.0.4)\nCollecting box2d-py==2.3.5 (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0)\n  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d,classic-control]>=1.1.1->main==0.1.0) (2.6.1)\nRequirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (0.2.2)\nRequirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (1.8.0)\nRequirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (7.34.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (8.6.3)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (5.7.2)\nRequirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (0.1.7)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (1.6.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (7.0.0)\nRequirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (24.0.1)\nRequirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (6.4.2)\nRequirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.29.5->main==0.1.0) (5.7.1)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.10.4->main==0.1.0) (2.21.1)\nRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.10.4->main==0.1.0) (4.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->main==0.1.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->main==0.1.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->main==0.1.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->main==0.1.0) (1.3.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (3.20.3)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.11.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.19.9->main==0.1.0) (75.2.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.19.9->main==0.1.0) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.19.9->main==0.1.0) (4.0.12)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (3.0.50)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->main==0.1.0) (0.24.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.29.5->main==0.1.0) (2.9.0.post0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.19.9->main==0.1.0) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.19.9->main==0.1.0) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->main==0.1.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->main==0.1.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->main==0.1.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.19.9->main==0.1.0) (5.0.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.4->main==0.1.0) (2024.2.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.29.5->main==0.1.0) (0.2.13)\nDownloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\nDownloading gymnasium-1.2.0-py3-none-any.whl (944 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.3/944.3 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nBuilding wheels for collected packages: main, box2d-py\n  Building wheel for main (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for main: filename=main-0.1.0-py3-none-any.whl size=11117 sha256=9fb7ea2f01bc365475df6b9d0cdcafe1f4ba9438cadf316fe27e6822db6091ca\n  Stored in directory: /tmp/pip-ephem-wheel-cache-5bkc5pys/wheels/4f/16/b7/f0afc1a4a4574831edbabf07feb162c98e9e62978951f878e1\n  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379367 sha256=67e5a5f92eed6f4a8643125d8c3ec2d16c5f2b3f8596349b5fc87798fd8beace\n  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\nSuccessfully built main box2d-py\nInstalling collected packages: box2d-py, python-dotenv, pip, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dotenv, nvidia-cusolver-cu12, ipykernel, gymnasium, main\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: ipykernel\n    Found existing installation: ipykernel 6.17.1\n    Uninstalling ipykernel-6.17.1:\n      Successfully uninstalled ipykernel-6.17.1\n  Attempting uninstall: gymnasium\n    Found existing installation: gymnasium 0.29.0\n    Uninstalling gymnasium-0.29.0:\n      Successfully uninstalled gymnasium-0.29.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.16.11 requires gymnasium==0.29.0, but you have gymnasium 1.2.0 which is incompatible.\nstable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.2.0 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires ipykernel==6.17.1, but you have ipykernel 6.29.5 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed box2d-py-2.3.5 dotenv-0.9.9 gymnasium-1.2.0 ipykernel-6.29.5 main-0.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pip-25.1.1 python-dotenv-1.1.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"id":"9b612218","cell_type":"markdown","source":"### 📊 Weights & Biases (W&B) Integration","metadata":{"papermill":{"duration":0.079339,"end_time":"2025-06-28T22:05:48.505751","exception":false,"start_time":"2025-06-28T22:05:48.426412","status":"completed"},"tags":[]}},{"id":"96190ea2","cell_type":"markdown","source":"Follow these steps to set up tracking with [Weights & Biases](https://wandb.ai/site/):\n\n1. [Create a W&B account](https://wandb.ai/site/).\n2. Set the `WANDB_ID` variable in the **Student Information** section to your W&B username.\n3. Create a new project using the name defined in the `PROJECT_NAME` variable. Ensure the project visibility is set to **Public**.\n4. [Retrieve your W&B API key](https://docs.wandb.ai/support/find_api_key/).\n5. Set the `WANDB_API_KEY`:\n   - As a **secret** if you're using **Google Colab** or **Kaggle**\n   - As an **environment variable** if running locally","metadata":{"papermill":{"duration":0.03228,"end_time":"2025-06-28T22:05:48.570665","exception":false,"start_time":"2025-06-28T22:05:48.538385","status":"completed"},"tags":[]}},{"id":"0bc175af","cell_type":"markdown","source":"#### 💻 Platform-Specific Setup","metadata":{"papermill":{"duration":0.031435,"end_time":"2025-06-28T22:05:48.633718","exception":false,"start_time":"2025-06-28T22:05:48.602283","status":"completed"},"tags":[]}},{"id":"51193d85","cell_type":"markdown","source":"##### Google Colab","metadata":{"papermill":{"duration":0.03121,"end_time":"2025-06-28T22:05:48.696908","exception":false,"start_time":"2025-06-28T22:05:48.665698","status":"completed"},"tags":[]}},{"id":"e43bf076","cell_type":"markdown","source":"\n> You only need to add the secret — no code changes are required.\n\n<img src=\"data:image/png;base64,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\">","metadata":{"papermill":{"duration":0.030745,"end_time":"2025-06-28T22:05:48.758693","exception":false,"start_time":"2025-06-28T22:05:48.727948","status":"completed"},"tags":[]}},{"id":"b761efed","cell_type":"markdown","source":"#### Kaggle","metadata":{"papermill":{"duration":0.031235,"end_time":"2025-06-28T22:05:48.820989","exception":false,"start_time":"2025-06-28T22:05:48.789754","status":"completed"},"tags":[]}},{"id":"3e867855","cell_type":"markdown","source":"To configure W&B API key in Kaggle:\n\n- Go to: `Add-ons` → `Secrets` → `Add Secret`\n- **Label:** `WANDB_API_KEY`  \n- **Value:** `<your_api_key>`\n\n> You only need to add the secret — no code changes are required.","metadata":{"papermill":{"duration":0.030442,"end_time":"2025-06-28T22:05:48.882355","exception":false,"start_time":"2025-06-28T22:05:48.851913","status":"completed"},"tags":[]}},{"id":"9bab74c8","cell_type":"markdown","source":"#### Local","metadata":{"papermill":{"duration":0.030694,"end_time":"2025-06-28T22:05:48.943963","exception":false,"start_time":"2025-06-28T22:05:48.913269","status":"completed"},"tags":[]}},{"id":"cfe444ce","cell_type":"markdown","source":"You can set the `WANDB_API_KEY` as an environment variable manually or,\n\nstore it in a `.env` file:\n```bash\n# secrets.env\nWANDB_API_KEY=your_api_key\n```\nand then run the following cell:","metadata":{"papermill":{"duration":0.030664,"end_time":"2025-06-28T22:05:49.005615","exception":false,"start_time":"2025-06-28T22:05:48.974951","status":"completed"},"tags":[]}},{"id":"f9fa4b9b","cell_type":"code","source":"from bootstrapdqn import get_machine\nif get_machine() == \"Local Machine\":\n    import dotenv\n    dotenv.load_dotenv(\".workspace/secrets.env\") # give it the path to your secrets.env file","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:10:58.333851Z","iopub.execute_input":"2025-06-29T07:10:58.334228Z","iopub.status.idle":"2025-06-29T07:11:03.842235Z","shell.execute_reply.started":"2025-06-29T07:10:58.334198Z","shell.execute_reply":"2025-06-29T07:11:03.841658Z"},"papermill":{"duration":5.622123,"end_time":"2025-06-28T22:05:54.658498","exception":false,"start_time":"2025-06-28T22:05:49.036375","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"c033e54f","cell_type":"markdown","source":"### 📤 Submission Requirements","metadata":{"papermill":{"duration":0.030993,"end_time":"2025-06-28T22:05:54.723621","exception":false,"start_time":"2025-06-28T22:05:54.692628","status":"completed"},"tags":[]}},{"id":"196a7c2a","cell_type":"markdown","source":"In addition to submitting this notebook on **Quera**, you must:\n\n- Have a W&B project matching the name in `PROJECT_NAME`, under the account defined by `WANDB_ID`\n- Ensure the W&B link displayed in the **Student Information** section is valid\n- Tag your final experiment run for **each algorithm** with `Final`:\n  - Go to **Runs** (left sidebar) → **Tags** → Add the tag `Final`\n  - A total of **four** runs should be tagged as `Final`\n\n⚠️ **Important:** The `save_code` option must remain enabled. If a `Final` run does not include saved code, it will **not** be graded.","metadata":{"papermill":{"duration":0.030697,"end_time":"2025-06-28T22:05:54.785791","exception":false,"start_time":"2025-06-28T22:05:54.755094","status":"completed"},"tags":[]}},{"id":"7f79ddfa","cell_type":"markdown","source":"### 🧮 Grading Criteria","metadata":{"papermill":{"duration":0.03082,"end_time":"2025-06-28T22:05:54.847945","exception":false,"start_time":"2025-06-28T22:05:54.817125","status":"completed"},"tags":[]}},{"id":"b3a734d4","cell_type":"markdown","source":"The score for each algorithm is provided in its respective section. This score is then multiplied by the environment score:\n- `CartPole`: × 0.1\n    - Minimum requirement: over 200 points across 5 consecutive evaluations\n- `LunarLander`: × 0.7\n    - Minimum requirement: over 200 points across 5 consecutive evaluations\n- `MountainCar`: × 1.0\n    - Minimum requirement: reach the goal state across 5 consecutive evaluations\n- `FrozenLake`: × 1.2\n    - Minimum requirement: reach the goal state across at least 5 evaluations of 15 consecutive evaluations\n- `SeaQuest`: × 1.5\n    -  Minimum requirement: over 2000 points across 5 consecutive evaluations\n\nTotal Score is 100. you can get up to 80 bonus score (180)","metadata":{"papermill":{"duration":0.031089,"end_time":"2025-06-28T22:05:54.910179","exception":false,"start_time":"2025-06-28T22:05:54.879090","status":"completed"},"tags":[]}},{"id":"06f395fc","cell_type":"markdown","source":"### 📝 Implementation Guide","metadata":{"papermill":{"duration":0.031024,"end_time":"2025-06-28T22:05:54.972217","exception":false,"start_time":"2025-06-28T22:05:54.941193","status":"completed"},"tags":[]}},{"id":"8874813a","cell_type":"markdown","source":"- Implement the algorithms as subclasses of `BaseDQNAgent` provided in [`base_agent.py`](https://github.com/DeepRLCourse/Homework-10/blob/main/BootstrapDQN/src/bootstrapdqn/base_agent.py). You may add or override methods/properties as needed.\n    - The `BaseDQNAgent` code will be automatically downloaded and imported. Ensure you review it carefully before implementing your algorithms.\n- Code blocks or lines marked with `# DO NOT CHANGE` must remain unaltered in your final submission. You may modify them during development for debugging purposes, but revert them before submitting.\n- If running locally, real-time W&B logging might face restrictions. Use W&B's offline mode for experiments and sync them later using the `wandb sync` command ([link](https://docs.wandb.ai/support/run_wandb_offline/)).\n- Prioritize vector operations over loops for better performance. While algorithm descriptions might use loops for clarity, only the main training and rollout loops (implemented in `BaseDQNAgent`) should remain iterative. Failure to vectorize may significantly increase convergence time.\n- For potentially more stable and faster training, you may consider using *Smooth L1 Loss* instead of Mean Squared Error. (Optional)\n- Weight initialization significantly impacts performance. Orthogonal initialization is generally recommended in the RL community and might be worth trying.\n","metadata":{"papermill":{"duration":0.031109,"end_time":"2025-06-28T22:05:55.034436","exception":false,"start_time":"2025-06-28T22:05:55.003327","status":"completed"},"tags":[]}},{"id":"eb917397","cell_type":"markdown","source":"### 💡 Tips & More","metadata":{"papermill":{"duration":0.030731,"end_time":"2025-06-28T22:05:55.096300","exception":false,"start_time":"2025-06-28T22:05:55.065569","status":"completed"},"tags":[]}},{"id":"65995fba","cell_type":"markdown","source":"The following resource provides general advice for implementing and debugging RL algorithms (not required for this homework, but highly recommended):\n\n- [Debugging RL, Without the Agonizing Pain](https://andyljones.com/posts/rl-debugging.html)","metadata":{"papermill":{"duration":0.031226,"end_time":"2025-06-28T22:05:55.159369","exception":false,"start_time":"2025-06-28T22:05:55.128143","status":"completed"},"tags":[]}},{"id":"b4975936","cell_type":"markdown","source":"# 🧭 Exploration Techniques in DQN","metadata":{"papermill":{"duration":0.030784,"end_time":"2025-06-28T22:05:55.221057","exception":false,"start_time":"2025-06-28T22:05:55.190273","status":"completed"},"tags":[]}},{"id":"25feac31","cell_type":"markdown","source":"## 🚀 Initialization\n","metadata":{"papermill":{"duration":0.03172,"end_time":"2025-06-28T22:05:55.286070","exception":false,"start_time":"2025-06-28T22:05:55.254350","status":"completed"},"tags":[]}},{"id":"9abbbf64","cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\nfrom bootstrapdqn import ReplayBuffer, BaseDQNAgent, get_machine, set_wandb_key_form_secrets, envs\nimport torch\nfrom torch import nn\nimport wandb\nimport random\nimport gymnasium as gym\nimport ale_py\n\ngym.register_envs(ale_py)","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:03.843029Z","iopub.execute_input":"2025-06-29T07:11:03.843495Z","iopub.status.idle":"2025-06-29T07:11:03.939681Z","shell.execute_reply.started":"2025-06-29T07:11:03.843468Z","shell.execute_reply":"2025-06-29T07:11:03.939168Z"},"papermill":{"duration":0.126518,"end_time":"2025-06-28T22:05:55.445591","exception":false,"start_time":"2025-06-28T22:05:55.319073","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":6},{"id":"2a41b04e","cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\nTA = True if WANDB_ID == \"alireza9\" else False\nSAVE_CODE = False if TA else True","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:03.940299Z","iopub.execute_input":"2025-06-29T07:11:03.940462Z","iopub.status.idle":"2025-06-29T07:11:03.944021Z","shell.execute_reply.started":"2025-06-29T07:11:03.940447Z","shell.execute_reply":"2025-06-29T07:11:03.943434Z"},"papermill":{"duration":0.035851,"end_time":"2025-06-28T22:05:55.513123","exception":false,"start_time":"2025-06-28T22:05:55.477272","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"id":"76d20abf","cell_type":"code","source":"# DO NOT CHANGE THIS BLOCK\n# IF YOU CHANGE ANYTHING ABOUT ENVIRONMENTS AND THEIR RUN CONFIGS, YOUR CODE WILL NOT BE GRADED\nfrom pprint import pprint\nENVS = envs()\npprint(ENVS)","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:03.944770Z","iopub.execute_input":"2025-06-29T07:11:03.945024Z","iopub.status.idle":"2025-06-29T07:11:03.956401Z","shell.execute_reply.started":"2025-06-29T07:11:03.944997Z","shell.execute_reply":"2025-06-29T07:11:03.955909Z"},"papermill":{"duration":0.038087,"end_time":"2025-06-28T22:05:55.582874","exception":false,"start_time":"2025-06-28T22:05:55.544787","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"{'CartPole': {'env': {'env_config': {}, 'env_name': 'CartPole-v1', 'seed': 43},\n              'run': {'max_episodes': 1000,\n                      'max_steps': 50000,\n                      'max_steps_per_episode': 100000,\n                      'max_time': 720.0}},\n 'FrozenLake': {'env': {'env_config': {'p': 0.87, 'size': 14},\n                        'env_name': 'FrozenLake-v1',\n                        'seed': 42},\n                'run': {'max_episodes': 1000000,\n                        'max_steps': 1000000,\n                        'max_steps_per_episode': 100000,\n                        'max_time': 14400}},\n 'LunarLander': {'env': {'env_config': {},\n                         'env_name': 'LunarLander-v3',\n                         'seed': 43},\n                 'run': {'max_episodes': 100000,\n                         'max_steps': 200000,\n                         'max_steps_per_episode': 100000,\n                         'max_time': 7200}},\n 'MountainCar': {'env': {'env_config': {},\n                         'env_name': 'MountainCar-v0',\n                         'seed': 43},\n                 'run': {'max_episodes': 100000,\n                         'max_steps': 300000,\n                         'max_steps_per_episode': 100000,\n                         'max_time': 9000.0}},\n 'SeaQuest': {'env': {'env_config': {},\n                      'env_name': 'Seaquest-ramNoFrameskip-v4',\n                      'seed': 43},\n              'run': {'max_episodes': 1000000,\n                      'max_steps': 2000000,\n                      'max_steps_per_episode': 1000000,\n                      'max_time': 28800}}}\n","output_type":"stream"}],"execution_count":8},{"id":"e88ed30d","cell_type":"code","source":"if not DEBUG:\n    set_wandb_key_form_secrets()","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:03.957105Z","iopub.execute_input":"2025-06-29T07:11:03.957353Z","iopub.status.idle":"2025-06-29T07:11:04.074343Z","shell.execute_reply.started":"2025-06-29T07:11:03.957336Z","shell.execute_reply":"2025-06-29T07:11:04.073636Z"},"papermill":{"duration":0.118626,"end_time":"2025-06-28T22:05:55.732530","exception":false,"start_time":"2025-06-28T22:05:55.613904","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"your machine is detected as Kaggle\n","output_type":"stream"}],"execution_count":9},{"id":"fae6529a","cell_type":"markdown","source":"## 💻 Algorithms Implementation","metadata":{"papermill":{"duration":0.03116,"end_time":"2025-06-28T22:05:55.795440","exception":false,"start_time":"2025-06-28T22:05:55.764280","status":"completed"},"tags":[]}},{"id":"60d14bd8","cell_type":"markdown","source":"### Epsilon Greedy DQN","metadata":{"papermill":{"duration":0.031543,"end_time":"2025-06-28T22:05:55.858557","exception":false,"start_time":"2025-06-28T22:05:55.827014","status":"completed"},"tags":[]}},{"id":"c9d1a56c","cell_type":"markdown","source":"Consider the following implementation as a reference for implementing other algorithms.\n\nYou can also use it as a baseline for comparing the performance of subsequent algorithms.","metadata":{"papermill":{"duration":0.03139,"end_time":"2025-06-28T22:05:55.921903","exception":false,"start_time":"2025-06-28T22:05:55.890513","status":"completed"},"tags":[]}},{"id":"c73f2f81","cell_type":"code","source":"class EpsGreedyDQNAgent(BaseDQNAgent):\n    \"\"\"\n    Epsilon-greedy DQN agent.\n    \"\"\"\n\n    def __init__(self, epsilon: float = 0.1, eps_decay: float = 0.999, eps_min: float = 0.01, **kwargs):\n        super().__init__(**kwargs)\n        self.epsilon = epsilon\n        self.eps_decay = eps_decay\n        self.eps_min = eps_min\n\n    def _decay_eps(self):\n        \"\"\"\n        Decay the epsilon value.\n        \"\"\"\n        self.epsilon = max(self.epsilon * self.eps_decay, self.eps_min)\n\n    def _create_replay_buffer(self, max_size=1000000):\n        self.replay_buffer = ReplayBuffer(\n            [\n                (\"state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"action\", (), torch.int64),\n                (\"reward\", (), torch.float32),\n                (\"next_state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"done\", (), torch.float32),\n            ],\n            max_size=max_size,\n            device=self.device,\n        )\n\n    def _create_network(self):\n        self.q_network = nn.Sequential(\n            nn.Linear(self.env.observation_space.shape[0], 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, self.env.action_space.n),\n        ).to(self.device)\n        self.q_network.apply(\n            lambda m: torch.nn.init.orthogonal_(m.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n            if isinstance(m, nn.Linear)\n            else None\n        )\n        self.target_network = nn.Sequential(\n            nn.Linear(self.env.observation_space.shape[0], 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, self.env.action_space.n),\n        ).to(self.device)\n\n    def _compute_loss(self, batch):\n        \"\"\"\n        Compute the loss for the DQN agent.\n        \"\"\"\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n\n        q_values = self.q_network(states).gather(1, actions.unsqueeze(1)).squeeze()\n        next_q_values = self.target_network(next_states).max(1)[0]\n        expected_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n\n        loss = nn.SmoothL1Loss()(q_values, expected_q_values)\n        return loss\n\n    def _act_in_training(self, state):\n        \"\"\"\n        Select an action during training.\n        \"\"\"\n        self._decay_eps()\n        if torch.rand(1).item() < self.epsilon:\n            return self.env.action_space.sample()\n        else:\n            with torch.no_grad():\n                q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n                return q_values.argmax().item()\n\n    def _act_in_eval(self, state):\n        \"\"\"\n        Select an action during evaluation.\n        \"\"\"\n        with torch.no_grad():\n            q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n            return q_values.argmax().item()\n\n    def _wandb_train_step_dict(self):\n        log_dict = super()._wandb_train_step_dict()\n        log_dict[\"train_step/epsilon\"] = self.epsilon\n        return log_dict\n\n    def _save_dict(self):\n        save_dict = super()._save_dict()\n        save_dict[\"epsilon\"] = self.epsilon\n        save_dict[\"eps_decay\"] = self.eps_decay\n        save_dict[\"eps_min\"] = self.eps_min\n        return save_dict\n","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:04.076474Z","iopub.execute_input":"2025-06-29T07:11:04.076686Z","iopub.status.idle":"2025-06-29T07:11:04.088241Z","shell.execute_reply.started":"2025-06-29T07:11:04.076672Z","shell.execute_reply":"2025-06-29T07:11:04.087400Z"},"papermill":{"duration":0.045028,"end_time":"2025-06-28T22:05:55.998324","exception":false,"start_time":"2025-06-28T22:05:55.953296","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"da5cf404","cell_type":"markdown","source":"### Bootstrap DQN","metadata":{"papermill":{"duration":0.031539,"end_time":"2025-06-28T22:05:56.061528","exception":false,"start_time":"2025-06-28T22:05:56.029989","status":"completed"},"tags":[]}},{"id":"68a18a04","cell_type":"markdown","source":"> Paper: [Deep Exploration via Bootstrapped DQN](https://arxiv.org/abs/1602.04621)\n\n**40 Points**","metadata":{"papermill":{"duration":0.031451,"end_time":"2025-06-28T22:05:56.124177","exception":false,"start_time":"2025-06-28T22:05:56.092726","status":"completed"},"tags":[]}},{"id":"e1783fc5","cell_type":"markdown","source":"#### Details\n\nIn this algorithm, instead of using a single network, we maintain an ensemble of networks (or a single network with multiple heads). At the start of each training episode, we randomly select one of these networks (heads) and use it to choose actions for the entire episode. This strategy approximates Thompson Sampling for the K-armed Bandit problem, enabling deeper exploration by leveraging the diversity among the ensemble members.","metadata":{"papermill":{"duration":0.030809,"end_time":"2025-06-28T22:05:56.186796","exception":false,"start_time":"2025-06-28T22:05:56.155987","status":"completed"},"tags":[]}},{"id":"31d6b09f","cell_type":"markdown","source":"#### Implementation","metadata":{"papermill":{"duration":0.030815,"end_time":"2025-06-28T22:05:56.248829","exception":false,"start_time":"2025-06-28T22:05:56.218014","status":"completed"},"tags":[]}},{"id":"0b54eaec","cell_type":"code","source":"from torch.distributions import Bernoulli\nimport torch.nn.functional as F\n\nclass MultiHeadQNet(nn.Module):\n    \"\"\"\n    A Q-network with a shared body and multiple independent \"heads\".\n    Each head provides a separate estimate of the Q-values, which is the core\n    idea behind bootstrapped DQN for estimating model uncertainty.\n    \"\"\"\n    def __init__(self, state_dim: int, action_dim: int, k: int, hidden_dim: int = 256):\n        \"\"\"\n        Initializes the network architecture.\n\n        Args:\n            state_dim: The dimensionality of the state space.\n            action_dim: The number of possible actions.\n            k: The number of heads for the Q-network.\n            hidden_dim: The size of the hidden layers.\n        \"\"\"\n        super().__init__()\n        self.k = k\n        self.action_dim = action_dim\n\n        # A shared feature extractor for all heads.\n        self.body = nn.Sequential(\n            nn.Linear(state_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU()\n        )\n\n        # A list of independent linear layers, one for each head.\n        self.heads = nn.ModuleList([nn.Linear(hidden_dim, action_dim) for _ in range(k)])\n\n        # Initialize weights for better training stability.\n        self._init_weights()\n\n    def _init_weights(self):\n        \"\"\"Applies orthogonal initialization to the network's linear layers.\"\"\"\n        for module in self.body:\n            if isinstance(module, nn.Linear):\n                torch.nn.init.orthogonal_(module.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n\n        for head in self.heads:\n            torch.nn.init.orthogonal_(head.weight, gain=torch.nn.init.calculate_gain(\"relu\"))\n\n    def forward(self, x: torch.Tensor, head_idx: int = None) -> torch.Tensor:\n        \"\"\"\n        Performs the forward pass through the network.\n\n        Args:\n            x: The input state tensor.\n            head_idx: If specified, returns Q-values for only this head. Otherwise,\n                      returns Q-values for all heads.\n\n        Returns:\n            A tensor of Q-values. The shape is (batch_size, action_dim) if head_idx is\n            specified, or (batch_size, num_heads, action_dim) otherwise.\n        \"\"\"\n        shared_features = self.body(x)\n\n        if head_idx is not None:\n            # Return the output for a single, specific head.\n            return self.heads[head_idx](shared_features)\n        else:\n            # Return the outputs for all heads, stacked along a new dimension.\n            outputs = [head(shared_features) for head in self.heads]\n            return torch.stack(outputs, dim=1)\n\n\nclass BootstrapDQNAgent(EpsGreedyDQNAgent):\n    \"\"\"\n    Bootstrap DQN agent, which uses an ensemble of Q-networks (heads)\n    to estimate uncertainty and guide exploration.\n    \"\"\"\n\n    def __init__(self, k: int = 10, bernoulli_p: float = 0.5, **kwargs):\n        \"\"\"\n        Initializes the agent's parameters.\n\n        Args:\n            k: The number of heads in the Q-network ensemble.\n            bernoulli_p: The probability for the bootstrap mask. Each head\n                         is trained on a transition with this probability.\n        \"\"\"\n        self.k = k\n        super().__init__(**kwargs)\n        self.bernoulli_p = bernoulli_p\n\n        # This distribution generates the masks for bootstrapping.\n        self.bernoulli_dist = Bernoulli(self.bernoulli_p)\n\n        # The active head used for action selection during a training episode.\n        self.current_head = 0\n\n    def _create_network(self):\n        \"\"\"Creates the multi-headed Q-network and its corresponding target network.\"\"\"\n        self.q_network = MultiHeadQNet(\n            state_dim=self.env.observation_space.shape[0],\n            action_dim=self.env.action_space.n,\n            k=self.k\n        ).to(self.device)\n\n        self.target_network = MultiHeadQNet(\n            state_dim=self.env.observation_space.shape[0],\n            action_dim=self.env.action_space.n,\n            k=self.k\n        ).to(self.device)\n\n        # Ensure the target network starts with the same weights.\n        self.target_network.load_state_dict(self.q_network.state_dict())\n\n    def _create_replay_buffer(self, max_size=1000000):\n        \"\"\"Creates a replay buffer that also stores the bootstrap mask for each transition.\"\"\"\n        self.replay_buffer = ReplayBuffer(\n            [\n                (\"state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"action\", (), torch.int64),\n                (\"reward\", (), torch.float32),\n                (\"next_state\", (self.env.observation_space.shape[0],), torch.float32),\n                (\"done\", (), torch.float32),\n                (\"mask\", (self.k,), torch.float32),\n            ],\n            max_size=max_size,\n            device=self.device,\n        )\n\n    def _preprocess_add(self, state, action, reward, next_state, done) -> dict:\n        \"\"\"\n        Prepares an experience tuple for the replay buffer by generating a bootstrap mask\n        and converting all data to tensors on the correct device.\n        \"\"\"\n        # preprocess and normalize states\n        state = self._state_transformation(state)\n        next_state = self._state_transformation(next_state)\n        \n        # Convert all NumPy/Python data to PyTorch Tensors and move to the designated device.\n        state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n        action_tensor = torch.tensor(action, dtype=torch.long, device=self.device)\n        reward_tensor = torch.tensor(reward, dtype=torch.float32, device=self.device)\n        next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n        done_tensor = torch.tensor(done, dtype=torch.float32, device=self.device)\n        \n        # create the mask\n        mask_tensor = self.bernoulli_dist.sample((self.k,)).to(self.device)\n\n        # Return the data as a dictionary of tensors.\n        return {\n            \"state\": state_tensor,\n            \"action\": action_tensor,\n            \"reward\": reward_tensor,\n            \"next_state\": next_state_tensor,\n            \"done\": done_tensor,\n            \"mask\": mask_tensor,\n        }\n\n    def _compute_loss(self, batch: dict) -> torch.Tensor:\n        \"\"\"\n        Computes the loss for the Bootstrap DQN. The loss is computed as the\n        average of the individual losses from each head, where each head's loss\n        is calculated only on the subset of the batch specified by its mask.\n        \"\"\"\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        masks = batch[\"mask\"]\n\n        # Get Q-value predictions from all heads of the online network.\n        q_values_all_heads = self.q_network(states)\n\n        # Get target Q-values from the target network. No gradients are needed here.\n        with torch.no_grad():\n            next_q_values_all_heads = self.target_network(next_states)\n            next_q_values_max = next_q_values_all_heads.max(dim=2)[0]\n\n        total_loss = 0.0\n\n        # Iterate through each head to calculate its specific loss.\n        for head_idx in range(self.k):\n            # Get the Q-values for the actions that were actually taken.\n            q_values_for_head = q_values_all_heads[:, head_idx, :].gather(1, actions.unsqueeze(1)).squeeze()\n\n            # Calculate the Bellman target value for this head.\n            next_q_values = next_q_values_max[:, head_idx]\n            expected_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n\n            # Get the bootstrap mask for the current head.\n            head_mask = masks[:, head_idx]\n\n            # Calculate loss only for the samples where the mask is active (1).\n            if head_mask.sum() > 0:\n                # Use boolean indexing to select only the active samples for the loss calculation.\n                head_loss = F.smooth_l1_loss(\n                    q_values_for_head[head_mask == 1],\n                    expected_q_values[head_mask == 1]\n                )\n                total_loss += head_loss\n\n        # Return the average loss across all heads.\n        return total_loss / self.k\n\n    def _episode(self):\n        \"\"\"Called at the start of each training episode.\"\"\"\n        # Randomly select a single head to be used for action selection in this episode.\n        self.current_head = torch.randint(0, self.k, (1,)).item()\n        super()._episode()\n\n    def _act_in_training(self, state) -> int:\n        \"\"\"\n        Selects an action during training using an epsilon-greedy policy based on the\n        Q-values from the currently active head.\n        \"\"\"\n        self._decay_eps()\n        if random.random() < self.epsilon:\n            # Exploration: choose a random action.\n            return self.env.action_space.sample()\n        else:\n            # Exploitation: choose the best action according to the active head.\n            with torch.no_grad():\n                state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n                q_values = self.q_network(state_tensor, head_idx=self.current_head)\n                return q_values.argmax().item()\n\n    def _act_in_eval(self, state) -> int:\n        \"\"\"\n        Selects an action during evaluation by averaging the Q-values from all heads\n        to get a more robust estimate.\n        \"\"\"\n        with torch.no_grad():\n            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n            # Get Q-values from all heads.\n            q_values_all_heads = self.q_network(state_tensor)\n            # Average the Q-values across the heads.\n            q_values_avg = q_values_all_heads.mean(dim=1)\n            return q_values_avg.argmax().item()\n\n    def _wandb_train_episode_dict(self) -> dict:\n        \"\"\"Adds extra information to the dictionary for logging with Weights & Biases.\"\"\"\n        log_dict = super()._wandb_train_episode_dict()\n        log_dict[\"train_episode/current_head\"] = self.current_head\n        return log_dict\n\n    def _save_dict(self) -> dict:\n        \"\"\"Adds extra agent parameters to the dictionary for saving the model checkpoint.\"\"\"\n        save_dict = super()._save_dict()\n        save_dict[\"k\"] = self.k\n        save_dict[\"bernoulli_p\"] = self.bernoulli_p\n        save_dict[\"current_head\"] = self.current_head\n        return save_dict","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:04.089193Z","iopub.execute_input":"2025-06-29T07:11:04.089407Z","iopub.status.idle":"2025-06-29T07:11:04.111468Z","shell.execute_reply.started":"2025-06-29T07:11:04.089393Z","shell.execute_reply":"2025-06-29T07:11:04.110781Z"},"papermill":{"duration":0.053039,"end_time":"2025-06-28T22:05:56.332994","exception":false,"start_time":"2025-06-28T22:05:56.279955","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"id":"a945e950","cell_type":"markdown","source":"### Bootstrap DQN with Randomized Prior Function","metadata":{"papermill":{"duration":0.031323,"end_time":"2025-06-28T22:05:56.395888","exception":false,"start_time":"2025-06-28T22:05:56.364565","status":"completed"},"tags":[]}},{"id":"f5838645","cell_type":"markdown","source":"> Paper: [Randomized Prior Functions for Deep Reinforcement Learning](https://arxiv.org/abs/1806.03335)\n\n**25 Points**","metadata":{"papermill":{"duration":0.0309,"end_time":"2025-06-28T22:05:56.457985","exception":false,"start_time":"2025-06-28T22:05:56.427085","status":"completed"},"tags":[]}},{"id":"6b837458","cell_type":"markdown","source":"#### Details","metadata":{"papermill":{"duration":0.03089,"end_time":"2025-06-28T22:05:56.520424","exception":false,"start_time":"2025-06-28T22:05:56.489534","status":"completed"},"tags":[]}},{"id":"69962dbc","cell_type":"markdown","source":"This method is very similar to Bootstrap DQN, but introduces additional **non-trainable** networks (with multiple heads) called random priors. These priors are added to the Q-network outputs to encourage diversity among ensemble members, both across states and over time. During training, the Q-networks learn to compensate for the effect of these fixed random priors, which helps maintain exploration.\n\n##### Notes\n- Random prior networks are typically smaller (narrower and shallower) than the main Q-networks, so the Q-networks tend to distill their influence during training.\n- There is a $\\delta_\\mathrm{RPF}$ coefficient to control the strength of the random priors, but for simplicity, you can set $\\delta_\\mathrm{RPF}=1$ and omit tuning this hyperparameter.","metadata":{"papermill":{"duration":0.031182,"end_time":"2025-06-28T22:05:56.582667","exception":false,"start_time":"2025-06-28T22:05:56.551485","status":"completed"},"tags":[]}},{"id":"0efeb9b9","cell_type":"markdown","source":"#### Implementation","metadata":{"papermill":{"duration":0.03147,"end_time":"2025-06-28T22:05:56.645461","exception":false,"start_time":"2025-06-28T22:05:56.613991","status":"completed"},"tags":[]}},{"id":"d8e69b4e","cell_type":"code","source":"class PriorMultiHeadQNet(MultiHeadQNet):\n    \"\"\"\n    A multi-headed network that serves as a fixed, randomly initialized prior function.\n    Its weights are frozen after creation and are not trained. This network is\n    intentionally shallower than the main Q-network to provide a simple, diverse\n    baseline for each head.\n    \"\"\"\n    def __init__(self, state_dim: int, action_dim: int, k: int, hidden_dim: int = 128):\n        \"\"\"\n        Initializes the prior network. It inherits from MultiHeadQNet but uses a\n        smaller hidden dimension and freezes its parameters.\n        \"\"\"\n        # Initialize the network architecture using the parent class.\n        super().__init__(state_dim, action_dim, k, hidden_dim)\n\n        # Freeze the network's parameters to prevent them from being updated during training.\n        for param in self.parameters():\n            param.requires_grad = False\n\n\nclass RPFBootstrapDQNAgent(BootstrapDQNAgent):\n    \"\"\"\n    Implements a Bootstrap DQN agent enhanced with Randomized Prior Functions (RPF).\n    Each Q-head learns to estimate the Q-value as a sum of its main output and a\n    corresponding fixed, random prior function. This encourages structured and\n    diverse exploration among the heads.\n    \"\"\"\n\n    def _create_network(self):\n        \"\"\"\n        Creates the main Q-network, its target network, and the frozen prior network.\n        The prior network is shared across all heads and does not have a target version.\n        \"\"\"\n        # Create the main Q-network and target network using the parent's method.\n        super()._create_network()\n\n        # Create the single, frozen prior network.\n        self.prior_network = PriorMultiHeadQNet(\n            state_dim=self.env.observation_space.shape[0],\n            action_dim=self.env.action_space.n,\n            k=self.k\n        ).to(self.device)\n\n    def _act_in_training(self, state: torch.Tensor) -> int:\n        \"\"\"\n        Selects an action during training. For exploitation, it combines the Q-value\n        from the active head of the main network with its corresponding prior.\n        \"\"\"\n        self._decay_eps()\n\n        if random.random() < self.epsilon:\n            # Exploration: Select a random action.\n            return self.env.action_space.sample()\n        else:\n            # Exploitation: Select the best action based on the combined Q-value.\n            with torch.no_grad():\n                state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n\n                # Get Q-value from the active head of the main network.\n                q_value = self.q_network(state_tensor, head_idx=self.current_head)\n\n                # Get the value from the corresponding head of the prior network.\n                prior_value = self.prior_network(state_tensor, head_idx=self.current_head)\n\n                # The final Q-value estimate for action selection is the sum of the two.\n                total_q_value = q_value + prior_value\n\n                return total_q_value.argmax().item()\n\n    def _act_in_eval(self, state: torch.Tensor) -> int:\n        \"\"\"\n        Selects an action during evaluation by averaging the combined Q-values\n        (main network + prior network) across all heads for a robust estimate.\n        \"\"\"\n        with torch.no_grad():\n            state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n\n            # Get Q-values from all heads of the main and prior networks.\n            q_values_all = self.q_network(state_tensor)\n            prior_values_all = self.prior_network(state_tensor)\n\n            # Combine the values and then average across the heads.\n            combined_q_values = q_values_all + prior_values_all\n            avg_q_values = combined_q_values.mean(dim=1)\n\n            return avg_q_values.argmax().item()\n\n    def _compute_loss(self, batch: dict) -> torch.Tensor:\n        \"\"\"\n        Computes the loss for the RPF agent. The main Q-network is trained to\n        predict the residual between the Bellman target and the prior's value.\n        \"\"\"\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        masks = batch[\"mask\"]\n\n        # The network's raw prediction comes only from the main Q-network.\n        q_predictions = self.q_network(states)\n\n        with torch.no_grad():\n            # The full Q-value of the next state is the sum of the target and prior nets.\n            next_q_from_target = self.target_network(next_states)\n            next_q_from_prior = self.prior_network(next_states)\n            total_next_q = next_q_from_target + next_q_from_prior\n\n            # Find the best Q-value from this combined total for each head.\n            best_next_q_values = total_next_q.max(dim=2)[0]\n\n            # Get the prior's value for the current state and action.\n            current_prior_values = self.prior_network(states)\n\n        total_loss = 0.0\n        for head_idx in range(self.k):\n            # The network is trained to predict: r + gamma*max_a'Q_total(s',a') - P(s,a)\n            # This is the \"residual\" learning objective.\n\n            q_pred_for_action = q_predictions[:, head_idx, :].gather(1, actions.unsqueeze(1)).squeeze()\n            prior_for_action = current_prior_values[:, head_idx, :].gather(1, actions.unsqueeze(1)).squeeze()\n\n            # Define the target for the main Q-network's prediction.\n            target = rewards + (1 - dones) * self.gamma * best_next_q_values[:, head_idx] - prior_for_action\n\n            head_mask = masks[:, head_idx]\n            if head_mask.sum() > 0:\n                # Calculate loss only for samples where the head's mask is active.\n                head_loss = F.smooth_l1_loss(\n                    q_pred_for_action[head_mask == 1],\n                    target[head_mask == 1]\n                )\n                total_loss += head_loss\n\n        return total_loss / self.k\n","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:04.112378Z","iopub.execute_input":"2025-06-29T07:11:04.112604Z","iopub.status.idle":"2025-06-29T07:11:04.130229Z","shell.execute_reply.started":"2025-06-29T07:11:04.112588Z","shell.execute_reply":"2025-06-29T07:11:04.129543Z"},"papermill":{"duration":0.046172,"end_time":"2025-06-28T22:05:56.723681","exception":false,"start_time":"2025-06-28T22:05:56.677509","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":12},{"id":"274e6b7f","cell_type":"markdown","source":"### Uncertainty Estimation for Sample Efficient RPF Bootstrap DQN","metadata":{"papermill":{"duration":0.031143,"end_time":"2025-06-28T22:05:56.787902","exception":false,"start_time":"2025-06-28T22:05:56.756759","status":"completed"},"tags":[]}},{"id":"c6e2c265","cell_type":"markdown","source":"> Paper: [Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation](https://arxiv.org/abs/2201.01666)\n\n**35 Points**","metadata":{"papermill":{"duration":0.04356,"end_time":"2025-06-28T22:05:56.869978","exception":false,"start_time":"2025-06-28T22:05:56.826418","status":"completed"},"tags":[]}},{"id":"f26095ee","cell_type":"markdown","source":"#### Details","metadata":{"papermill":{"duration":0.031902,"end_time":"2025-06-28T22:05:56.933810","exception":false,"start_time":"2025-06-28T22:05:56.901908","status":"completed"},"tags":[]}},{"id":"90112b11","cell_type":"markdown","source":"This method does not explicitly address the exploration problem but focuses on improving sample efficiency.\n\nBy maintaining an ensemble of Q-networks, multiple Q-values can be computed for each state-action pair. This enables the estimation of uncertainty in the target values. Using this uncertainty, a weighted loss is calculated, where the weights are inversely proportional to the uncertainty. The more confident we are about a target, the higher its weight during the update.","metadata":{"papermill":{"duration":0.031867,"end_time":"2025-06-28T22:05:56.997487","exception":false,"start_time":"2025-06-28T22:05:56.965620","status":"completed"},"tags":[]}},{"id":"e847b869","cell_type":"markdown","source":"Logging Effective Batch Size (EBS) helps you to tune $\\xi$ parameter:\n\n$$\nEBS = \\dfrac{\\left(\\sum^K_k w_k\\right)^2}{\\sum_k^K w_k^2} = \\dfrac{\\left(\\sum_k^K \\dfrac{1}{(\\sigma_k^2 + \\xi)}\\right)^2}{\\sum_k^K\\dfrac{1}{(\\sigma_k^2 + \\xi)^2}} \n$$","metadata":{"papermill":{"duration":0.044124,"end_time":"2025-06-28T22:05:57.075128","exception":false,"start_time":"2025-06-28T22:05:57.031004","status":"completed"},"tags":[]}},{"id":"eaed9b66","cell_type":"markdown","source":"#### Bonus","metadata":{"papermill":{"duration":0.031576,"end_time":"2025-06-28T22:05:57.139153","exception":false,"start_time":"2025-06-28T22:05:57.107577","status":"completed"},"tags":[]}},{"id":"50a3d56a","cell_type":"markdown","source":"1. Use the minimum Effective Batch Size (EBS) as a hyperparameter instead of $\\xi$, and numerically calculate $\\xi$ during each training step based on the minimum EBS. (5 points)\n2. Implement the complete IV-DQN algorithm as described in the appendix of the original paper. (15 points)","metadata":{"papermill":{"duration":0.035492,"end_time":"2025-06-28T22:05:57.206263","exception":false,"start_time":"2025-06-28T22:05:57.170771","status":"completed"},"tags":[]}},{"id":"8574a77a","cell_type":"markdown","source":"#### Implementation","metadata":{"papermill":{"duration":0.033466,"end_time":"2025-06-28T22:05:57.281421","exception":false,"start_time":"2025-06-28T22:05:57.247955","status":"completed"},"tags":[]}},{"id":"58a18cb6","cell_type":"code","source":"class UEBootstrapDQNAgent(RPFBootstrapDQNAgent):\n    \"\"\"\n    Implements an advanced Bootstrap DQN using Uncertainty-Weighted Regression, also known\n    as Batch Inverse Variance DQN. This agent dynamically adjusts its loss weighting\n    to maintain a minimum Effective Batch Size (EBS), ensuring stable learning.\n    \"\"\"\n\n    def __init__(self, min_effective_batch_size: float = 8.0, xi_init: float = 0.1, **kwargs):\n        \"\"\"\n        Initializes the agent. The `xi` parameter is now dynamically tuned and not\n        a fixed hyperparameter for exploration bonus.\n\n        Args:\n            min_effective_batch_size: The target minimum effective batch size. This is the\n                                      key hyperparameter for this agent.\n            xi_init: The initial value for the uncertainty scaling parameter, xi.\n        \"\"\"\n        # The parent's __init__ is called, but we are overriding the meaning of xi.\n        # The provided xi=0.5 in the template is ignored in favor of these parameters.\n        super().__init__(**kwargs)\n        self.min_effective_batch_size = min_effective_batch_size\n        self.xi = xi_init\n\n        # Parameters for the dynamic xi update rule.\n        self.xi_update_rate = 0.01\n        self.xi_min = 1e-6\n        self.xi_max = 100.0\n\n        # Placeholders for logging important metrics.\n        self.last_effective_batch_size = None\n        self.last_mean_uncertainty = None\n\n    def _compute_dynamic_xi(self, target_variance: torch.Tensor) -> float:\n        \"\"\"\n        Dynamically calculates the `xi` parameter to ensure the effective batch\n        size (EBS) from uncertainty weighting doesn't fall below the specified minimum.\n        \"\"\"\n        with torch.no_grad():\n            batch_size = target_variance.shape[0]\n            # Calculate the loss weights and resulting EBS using the current xi.\n            weights = 1.0 / (target_variance + self.xi)\n            current_ebs = self._compute_effective_batch_size_from_weights(weights)\n\n            # If the current EBS is too low, find a new xi that increases it.\n            if current_ebs < self.min_effective_batch_size:\n                # Use binary search to find an xi that yields the target EBS.\n                low, high = self.xi_min, self.xi_max\n                for _ in range(10): # 10 iterations is sufficient for convergence.\n                    mid = (low + high) / 2\n                    test_weights = 1.0 / (target_variance + mid)\n                    test_ebs = self._compute_effective_batch_size_from_weights(test_weights)\n                    if test_ebs < self.min_effective_batch_size:\n                        low = mid\n                    else:\n                        high = mid\n                new_xi = high\n            else:\n                new_xi = self.xi\n\n            # Smoothly update xi towards the new target value to stabilize changes.\n            updated_xi = self.xi * (1 - self.xi_update_rate) + new_xi * self.xi_update_rate\n            return torch.clamp(torch.tensor(updated_xi), self.xi_min, self.xi_max).item()\n\n    def _compute_effective_batch_size_from_weights(self, weights: torch.Tensor) -> float:\n        \"\"\"Helper function to calculate the effective batch size given a set of weights.\"\"\"\n        with torch.no_grad():\n            sum_w = weights.sum()\n            sum_w_sq = (weights**2).sum()\n            return (sum_w**2 / sum_w_sq).item() if sum_w_sq > 0 else 0.0\n\n    def _compute_loss(self, batch: dict) -> torch.Tensor:\n        \"\"\"\n        Computes the uncertainty-weighted loss for each head, ensuring that the\n        bootstrap mask is correctly applied.\n        \"\"\"\n        states = batch[\"state\"]\n        actions = batch[\"action\"]\n        rewards = batch[\"reward\"]\n        next_states = batch[\"next_state\"]\n        dones = batch[\"done\"]\n        bootstrap_masks = batch[\"mask\"] # This is essential for bootstrapping.\n\n        batch_size = states.shape[0]\n\n        # Get Q-value predictions from the main online network.\n        q_predictions = self.q_network(states)\n\n        with torch.no_grad():\n            # --- Determine Target Q-Values using the Double DQN principle ---\n\n            # 1. Select best next action using the *online* network.\n            online_next_q = self.q_network(next_states)\n            online_next_prior = self.prior_network(next_states)\n            online_next_total = online_next_q + online_next_prior\n            next_actions = online_next_total.mean(dim=1).argmax(dim=1)\n\n            # 2. Evaluate that action's value using the *target* network.\n            target_next_q = self.target_network(next_states)\n            prior_next_q = self.prior_network(next_states) # No target_prior_network needed.\n            total_target_next_q = target_next_q + prior_next_q\n\n            next_actions_expanded = next_actions.unsqueeze(1).unsqueeze(2).expand(-1, self.k, -1)\n            best_next_q_values = total_target_next_q.gather(2, next_actions_expanded).squeeze(2)\n\n            # --- Calculate Uncertainty and Weights ---\n            target_q_values = rewards.unsqueeze(-1) + (1 - dones.unsqueeze(-1)) * self.gamma * best_next_q_values\n            target_variance = target_q_values.var(dim=1)\n\n            self.xi = self._compute_dynamic_xi(target_variance)\n\n            # Loss weights are inversely proportional to the variance (uncertainty).\n            uncertainty_weights = 1.0 / (target_variance + self.xi)\n            # Normalize weights to keep the learning rate scale consistent.\n            uncertainty_weights = uncertainty_weights * batch_size / uncertainty_weights.sum()\n\n            # Get prior values for the current state to calculate the residual target.\n            current_prior_values = self.prior_network(states)\n\n        total_loss = 0.0\n        for head_idx in range(self.k):\n            # The main network is trained to predict the residual target.\n            q_pred_for_action = q_predictions[:, head_idx, :].gather(1, actions.unsqueeze(1)).squeeze()\n            prior_for_action = current_prior_values[:, head_idx, :].gather(1, actions.unsqueeze(1)).squeeze()\n\n            target = rewards + (1 - dones) * best_next_q_values[:, head_idx] - prior_for_action\n\n            # Get the correct bootstrap mask for this specific head.\n            bootstrap_mask_for_head = bootstrap_masks[:, head_idx]\n\n            # Only compute loss for samples active in this head's bootstrap mask.\n            if bootstrap_mask_for_head.sum() > 0:\n                loss = F.smooth_l1_loss(q_pred_for_action, target, reduction='none')\n\n                # The final weight is the product of the uncertainty weight and the bootstrap mask.\n                combined_weights = uncertainty_weights * bootstrap_mask_for_head\n\n                # Apply the combined weights to the loss.\n                weighted_loss = (loss * combined_weights).sum() / combined_weights.sum()\n                total_loss += weighted_loss\n\n        # Log metrics for monitoring.\n        with torch.no_grad():\n            self.last_mean_uncertainty = target_variance.mean().item()\n            self.last_effective_batch_size = self._compute_effective_batch_size_from_weights(uncertainty_weights)\n\n        return total_loss / self.k\n\n    def _save_dict(self) -> dict:\n        \"\"\"Adds `xi` and `min_effective_batch_size` to the model checkpoint.\"\"\"\n        save_dict = super()._save_dict()\n        # The parent's _save_dict might save an old 'xi' from a different context,\n        # so we ensure it's removed before adding our specific parameters.\n        save_dict.pop('xi', None)\n        save_dict[\"xi\"] = self.xi\n        save_dict[\"min_effective_batch_size\"] = self.min_effective_batch_size\n        return save_dict\n\n    def _wandb_train_step_dict(self) -> dict:\n        \"\"\"Adds detailed diagnostics about the uncertainty weighting to the wandb logs.\"\"\"\n        log_dict = super()._wandb_train_step_dict()\n\n        # Add important metrics for diagnosing the agent's behavior.\n        log_dict[\"train/xi_dynamically_computed\"] = self.xi\n        log_dict[\"train/mean_target_variance\"] = self.last_mean_uncertainty if self.last_mean_uncertainty is not None else 0\n        log_dict[\"train/effective_batch_size\"] = self.last_effective_batch_size if self.last_effective_batch_size is not None else 0\n\n        # This ratio is useful to see if the EBS is hitting its target minimum.\n        if self.last_effective_batch_size is not None and self.min_effective_batch_size > 0:\n            log_dict[\"train/ebs_vs_target_ratio\"] = self.last_effective_batch_size / self.min_effective_batch_size\n\n        return log_dict","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:04.131034Z","iopub.execute_input":"2025-06-29T07:11:04.131743Z","iopub.status.idle":"2025-06-29T07:11:04.153121Z","shell.execute_reply.started":"2025-06-29T07:11:04.131721Z","shell.execute_reply":"2025-06-29T07:11:04.152505Z"},"papermill":{"duration":0.043289,"end_time":"2025-06-28T22:05:57.356261","exception":false,"start_time":"2025-06-28T22:05:57.312972","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"id":"70286b39","cell_type":"markdown","source":"## ⚙️ Configs","metadata":{"papermill":{"duration":0.031655,"end_time":"2025-06-28T22:05:57.429027","exception":false,"start_time":"2025-06-28T22:05:57.397372","status":"completed"},"tags":[]}},{"id":"40834d17","cell_type":"markdown","source":"Feel free to change hyperparameters","metadata":{"papermill":{"duration":0.031483,"end_time":"2025-06-28T22:05:57.492870","exception":false,"start_time":"2025-06-28T22:05:57.461387","status":"completed"},"tags":[]}},{"id":"ac145d7a","cell_type":"code","source":"env = [\"FrozenLake\", \"CartPole\", \"MountainCar\", \"SeaQuest\", \"LunarLander\"][2]\nprint(f\"{env} is selected.\")\n\nbase_agent_config = {\n    **ENVS[env][\"env\"],\n    \"default_batch_size\": 64,\n    \"gamma\": 0.99,\n    \"learning_rate\": 0.001,\n    \"replay_buffer_capacity\":25_000,\n    \"tau\": 5e-3,\n    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n    \"gradient_norm_clip\": 10.0,\n    \"start_training_after\": 1000,\n    \"normalize_rewards\": False,\n    \"scale_rewards\": None\n}\n\nbase_run_config = {\n    **ENVS[env][\"run\"],\n    \"learn_every\": 1,  # Apply learning every n steps of rollout\n    \"eval_every\": 10_000,  # Evaluate model approximately every n steps\n}","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:04.153868Z","iopub.execute_input":"2025-06-29T07:11:04.154085Z","iopub.status.idle":"2025-06-29T07:11:04.167899Z","shell.execute_reply.started":"2025-06-29T07:11:04.154066Z","shell.execute_reply":"2025-06-29T07:11:04.167224Z"},"papermill":{"duration":0.039073,"end_time":"2025-06-28T22:05:57.563424","exception":false,"start_time":"2025-06-28T22:05:57.524351","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"MountainCar is selected.\n","output_type":"stream"}],"execution_count":14},{"id":"5bd4f905","cell_type":"code","source":"eps_greedy_config = {\n    **base_agent_config,\n    \"eps_decay\": 0.9999,\n    \"eps_min\": 0.01,\n    \"epsilon\": 1.0,\n}","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:04.168641Z","iopub.execute_input":"2025-06-29T07:11:04.168842Z","iopub.status.idle":"2025-06-29T07:11:04.177174Z","shell.execute_reply.started":"2025-06-29T07:11:04.168830Z","shell.execute_reply":"2025-06-29T07:11:04.176559Z"},"papermill":{"duration":0.036819,"end_time":"2025-06-28T22:05:57.632202","exception":false,"start_time":"2025-06-28T22:05:57.595383","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":15},{"id":"fb8ef550","cell_type":"code","source":"bootstrap_dqn_config = {\n    **eps_greedy_config,\n    \"k\": 10,\n    \"bernoulli_p\": 0.6,\n}","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:04.177842Z","iopub.execute_input":"2025-06-29T07:11:04.178175Z","iopub.status.idle":"2025-06-29T07:11:04.187406Z","shell.execute_reply.started":"2025-06-29T07:11:04.178156Z","shell.execute_reply":"2025-06-29T07:11:04.186735Z"},"papermill":{"duration":0.037812,"end_time":"2025-06-28T22:05:57.702160","exception":false,"start_time":"2025-06-28T22:05:57.664348","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"id":"bee13f11","cell_type":"code","source":"rpf_bootstrap_dqn_config = {\n    **bootstrap_dqn_config,\n}","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:04.188183Z","iopub.execute_input":"2025-06-29T07:11:04.188353Z","iopub.status.idle":"2025-06-29T07:11:04.198060Z","shell.execute_reply.started":"2025-06-29T07:11:04.188339Z","shell.execute_reply":"2025-06-29T07:11:04.197225Z"},"papermill":{"duration":0.037073,"end_time":"2025-06-28T22:05:57.770825","exception":false,"start_time":"2025-06-28T22:05:57.733752","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"id":"a2bf0ceb","cell_type":"code","source":"ue_bootstrap_dqn_config = {\n    **rpf_bootstrap_dqn_config,\n    \"min_effective_batch_size\": 8,\n    \"xi_init\": 0.1,\n}","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:11:04.198799Z","iopub.execute_input":"2025-06-29T07:11:04.198976Z","iopub.status.idle":"2025-06-29T07:11:04.208203Z","shell.execute_reply.started":"2025-06-29T07:11:04.198962Z","shell.execute_reply":"2025-06-29T07:11:04.207469Z"},"papermill":{"duration":0.039455,"end_time":"2025-06-28T22:05:57.848050","exception":false,"start_time":"2025-06-28T22:05:57.808595","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"id":"05573a25","cell_type":"markdown","source":"## 🔄 Training","metadata":{"papermill":{"duration":0.033289,"end_time":"2025-06-28T22:05:57.913172","exception":false,"start_time":"2025-06-28T22:05:57.879883","status":"completed"},"tags":[]}},{"id":"e182950a","cell_type":"markdown","source":"The `try-except` block allows you to terminate the current algorithm's run directly from the W&B panel and proceed to the next algorithm without crashing the entire notebook. This can be particularly useful when using Kaggle's *Save Version* feature.","metadata":{"papermill":{"duration":0.031779,"end_time":"2025-06-28T22:05:57.977018","exception":false,"start_time":"2025-06-28T22:05:57.945239","status":"completed"},"tags":[]}},{"id":"dd4e1af5","cell_type":"markdown","source":"### Epsilon Greedy DQN","metadata":{"papermill":{"duration":0.031479,"end_time":"2025-06-28T22:05:58.040319","exception":false,"start_time":"2025-06-28T22:05:58.008840","status":"completed"},"tags":[]}},{"id":"08f95efd","cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"eps_greedy\",\n    \"config\": {**eps_greedy_config, **base_run_config, \"machine\": get_machine()},\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"eps_greedy\"],\n}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\neps_greedy_dqn_agent = EpsGreedyDQNAgent(wandb_run=wandb_run, **eps_greedy_config)","metadata":{"execution":{"iopub.execute_input":"2025-06-28T22:05:58.107270Z","iopub.status.busy":"2025-06-28T22:05:58.106689Z","iopub.status.idle":"2025-06-28T22:06:05.255883Z","shell.execute_reply":"2025-06-28T22:06:05.255072Z"},"papermill":{"duration":7.185198,"end_time":"2025-06-28T22:06:05.257242","exception":false,"start_time":"2025-06-28T22:05:58.072044","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielparnian\u001b[0m (\u001b[33mdanialpa\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250628_220559-8wwslyf8\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meps_greedy\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW/runs/8wwslyf8\u001b[0m\n"]}],"execution_count":19},{"id":"c53e729a","cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\ntry:\n    eps_greedy_dqn_agent.train(**base_run_config)\n    wandb_run.finish()\nexcept KeyboardInterrupt:\n    pass","metadata":{"execution":{"iopub.execute_input":"2025-06-28T22:06:05.323655Z","iopub.status.busy":"2025-06-28T22:06:05.323294Z","iopub.status.idle":"2025-06-28T22:34:08.166598Z","shell.execute_reply":"2025-06-28T22:34:08.165870Z"},"papermill":{"duration":1682.877263,"end_time":"2025-06-28T22:34:08.167922","exception":false,"start_time":"2025-06-28T22:06:05.290659","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","error: XDG_RUNTIME_DIR not set in the environment.\n","ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n","ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n","ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n","ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n","ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1646662812.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:457: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:460: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1646662812.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  q_values = self.q_network(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device))\n"]},{"name":"stdout","output_type":"stream","text":["Trained for 300000 steps.\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  eval_episode/episode_length ██▅█▁▄▃▃▅▄▂▄▄███▅█████████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:     eval_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      eval_episode/sum_reward ▁▁▄▁█▅▆▆▄▅▇▅▅▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_episode/episode_length ██▄▆█▇▆▇▁▆▅▃▃▃▃▅▂▂▃▁▅▅▅▄▅█▅█████████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train_episode/mean_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▃▄▇███▃▂▂▃▃▃▃▃▂▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_return ▁▁▁▃▃▄▅▆▆▆▇▇▇▇▇██████████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train_episode/sum_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▄▆▅▆█▆▂▂▂▂▂▃▃▃▃▂▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/sum_reward ▁▇▄▁▇▆▇▇██▄▄▅▅▅▅▄▁▅▃▅▅▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/var_return ▁▁▁▂▂▄▄▅▆▆▆▆▆▆▇██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:           train_step/epsilon █▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train_step/grad_norm ▁▁▁▁▂▁▂▂▆███████████████████████████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train_step/loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▃▂▃▄█▁▂▁▁▁▁▁▁▂▁▁▁▁▁▂\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  eval_episode/episode_length 200\n","\u001b[34m\u001b[1mwandb\u001b[0m:     eval_episode/mean_reward -1\n","\u001b[34m\u001b[1mwandb\u001b[0m:      eval_episode/sum_reward -200\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_episode/episode_length 12\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train_episode/mean_loss 7712.79318\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_return -79.51072\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_reward -1\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train_episode/sum_loss 92553.51819\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/sum_reward -12\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/var_return 78.5053\n","\u001b[34m\u001b[1mwandb\u001b[0m:           train_step/epsilon 0.01\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train_step/grad_norm 10.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train_step/loss 30042.94531\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33meps_greedy\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW/runs/8wwslyf8\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 30 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250628_220559-8wwslyf8/logs\u001b[0m\n"]}],"execution_count":20},{"id":"03ab6488","cell_type":"markdown","source":"### Bootstrap DQN","metadata":{"papermill":{"duration":0.034819,"end_time":"2025-06-28T22:34:08.238994","exception":false,"start_time":"2025-06-28T22:34:08.204175","status":"completed"},"tags":[]}},{"id":"11b7e9d3","cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"bootstrap\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\nbootstrap_dqn_agent = BootstrapDQNAgent(wandb_run=wandb_run, **bootstrap_dqn_config)","metadata":{"execution":{"iopub.execute_input":"2025-06-28T22:34:08.309674Z","iopub.status.busy":"2025-06-28T22:34:08.309212Z","iopub.status.idle":"2025-06-28T22:34:09.246135Z","shell.execute_reply":"2025-06-28T22:34:09.245531Z"},"papermill":{"duration":0.973738,"end_time":"2025-06-28T22:34:09.247432","exception":false,"start_time":"2025-06-28T22:34:08.273694","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250628_223408-rgzhnuwq\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbootstrap\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW/runs/rgzhnuwq\u001b[0m\n"]}],"execution_count":21},{"id":"5e55bb00","cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\ntry:\n    bootstrap_dqn_agent.train(**base_run_config)\n    wandb_run.finish()\nexcept KeyboardInterrupt:\n    pass","metadata":{"execution":{"iopub.execute_input":"2025-06-28T22:34:09.370184Z","iopub.status.busy":"2025-06-28T22:34:09.369917Z","iopub.status.idle":"2025-06-28T23:54:54.197723Z","shell.execute_reply":"2025-06-28T23:54:54.197047Z"},"papermill":{"duration":4844.865036,"end_time":"2025-06-28T23:54:54.198953","exception":false,"start_time":"2025-06-28T22:34:09.333917","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n","ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n","ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n","ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n","ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n"]},{"name":"stdout","output_type":"stream","text":["Trained for 300000 steps.\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  eval_episode/episode_length █▃▆▂▅▅▅▂▃▂▅▃▁▂▁█▂▂▂▂▁▂▂▁▂▁▁▅▅▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:     eval_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      eval_episode/sum_reward ▁▆▃▇▄▄▄▇▆▇▄▆█▇█▁▇▇▇▇█▇▇█▇██▄▄▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train_episode/current_head ▂▇▁▅█▆▅▆▃▂▄▇▄▃▄▆▇▁▇█▃▆▃▃▇█▁▂▇▃▄▆█▃▁▁▃▂▅▂\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_episode/episode_length ██▆█▅▂▄▄▅▂▁▁▂▁▃▇▅▆▁▃▁▃▂▂▂▁▁▃▃▄▃▁▁▃▂▂▄▄▃▆\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train_episode/mean_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_return ▁▁▁▁▁▂▃▃▃▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train_episode/sum_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▆█\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/sum_reward ▁▁▁▁▁▁▄▃▄▄▄▄▆█▆█▇▃██▇██▇▇▆▇█▇█▇▇▆▄▆█▃▇▆█\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/var_return ▁▁▁▂▂▃▃▃▃▄▅▆▆▇▇▇▇▇▇████████▇▇▇▇▇▇▇▇▇▇▇▇▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:           train_step/epsilon █▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train_step/grad_norm ▁▁▁▁▁▃▂▁▂▂▄▃██▅██▇█▄█▃██▄▆▃█▅▅▅██▇█▅██▄█\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train_step/loss ▁▁▁▁▁▁▁▁▁▁▃▁▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▂▁▃▃▂▃█\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  eval_episode/episode_length 142\n","\u001b[34m\u001b[1mwandb\u001b[0m:     eval_episode/mean_reward -1\n","\u001b[34m\u001b[1mwandb\u001b[0m:      eval_episode/sum_reward -142\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train_episode/current_head 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_episode/episode_length 95\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train_episode/mean_loss 117.30837\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_return -69.41132\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_reward -1\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train_episode/sum_loss 11144.29495\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/sum_reward -95\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/var_return 68.30077\n","\u001b[34m\u001b[1mwandb\u001b[0m:           train_step/epsilon 0.01\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train_step/grad_norm 10.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train_step/loss 58.44644\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbootstrap\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW/runs/rgzhnuwq\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 30 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250628_223408-rgzhnuwq/logs\u001b[0m\n"]}],"execution_count":22},{"id":"b46f392b","cell_type":"markdown","source":"### Bootstrap DQN with Randomized Prior Function","metadata":{"papermill":{"duration":0.038092,"end_time":"2025-06-28T23:54:54.331173","exception":false,"start_time":"2025-06-28T23:54:54.293081","status":"completed"},"tags":[]}},{"id":"a1fca5f4","cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"randomized_prior\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"rpf_bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**rpf_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\nrpf_bootstrap_dqn_agent = RPFBootstrapDQNAgent(wandb_run=wandb_run, **rpf_bootstrap_dqn_config)","metadata":{"execution":{"iopub.execute_input":"2025-06-28T23:54:54.410469Z","iopub.status.busy":"2025-06-28T23:54:54.410199Z","iopub.status.idle":"2025-06-28T23:54:55.287616Z","shell.execute_reply":"2025-06-28T23:54:55.286905Z"},"papermill":{"duration":0.919313,"end_time":"2025-06-28T23:54:55.288985","exception":false,"start_time":"2025-06-28T23:54:54.369672","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250628_235454-khxcxwcx\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrandomized_prior\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW/runs/khxcxwcx\u001b[0m\n"]}],"execution_count":23},{"id":"039788a3","cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\ntry:\n    rpf_bootstrap_dqn_agent.train(**base_run_config)\n    wandb_run.finish()\nexcept KeyboardInterrupt:\n    pass","metadata":{"execution":{"iopub.execute_input":"2025-06-28T23:54:55.373388Z","iopub.status.busy":"2025-06-28T23:54:55.372671Z","iopub.status.idle":"2025-06-29T01:21:55.655955Z","shell.execute_reply":"2025-06-29T01:21:55.655337Z"},"papermill":{"duration":5220.324791,"end_time":"2025-06-29T01:21:55.657139","exception":false,"start_time":"2025-06-28T23:54:55.332348","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n","ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n","ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n","ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n","ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(state, device=self.device),\n","/tmp/ipykernel_19/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n","/tmp/ipykernel_19/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","/tmp/ipykernel_19/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n"]},{"name":"stdout","output_type":"stream","text":["Trained for 300000 steps.\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  eval_episode/episode_length █▃█▅▅▅▆█▃▂▂▂▃▁▂▅▂▂▂▂▁▂▂▁▂▂▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     eval_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      eval_episode/sum_reward ▁▆▁▄▄▄▃▁▆▇▇▇▆█▇▄▇▇▇▇█▇▇█▇▇▇▇██\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train_episode/current_head ▃▆▆▃▇▅▅▆▆▆▃▄▂▆▃▄▅▆▇▂█▅▆▃▃▃▇▇▇█▁▁▇▇▂▆▇▄▁▆\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_episode/episode_length ████▅▆▃▄▃▂▂▂▁▃▄▃▇▂▃▄▂▂▂▂▂▁▂▂▂▂▂▂▂▁▁▂▂▁▁▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train_episode/mean_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃█\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_return ▁▁▁▁▂▂▂▂▃▃▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_reward ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train_episode/sum_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▆▅▆▆▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/sum_reward ▁▁▁▃█▃▄▆▄▅▆▆▇▇▇▆▂█▇▄▇▆▇▇▇█▇▇▇▇▇▅▇▇▇▇▇▇▇▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/var_return ▁▂▃▅▅▆▆▇▇▇█████████████▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆\n","\u001b[34m\u001b[1mwandb\u001b[0m:           train_step/epsilon █▇▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train_step/grad_norm ▁▁▁▁▂▃▂██▄▄▅▅█████▅▆████████████████████\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train_step/loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▄▂▃▃▂▅▁▁▁█▅▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  eval_episode/episode_length 83\n","\u001b[34m\u001b[1mwandb\u001b[0m:     eval_episode/mean_reward -1\n","\u001b[34m\u001b[1mwandb\u001b[0m:      eval_episode/sum_reward -83\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train_episode/current_head 3\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_episode/episode_length 5\n","\u001b[34m\u001b[1mwandb\u001b[0m:      train_episode/mean_loss 101.95667\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_return -68.09064\n","\u001b[34m\u001b[1mwandb\u001b[0m:    train_episode/mean_reward -1\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train_episode/sum_loss 509.78334\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/sum_reward -5\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train_episode/var_return 65.96442\n","\u001b[34m\u001b[1mwandb\u001b[0m:           train_step/epsilon 0.01\n","\u001b[34m\u001b[1mwandb\u001b[0m:         train_step/grad_norm 10.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train_step/loss 57.28342\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrandomized_prior\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW/runs/khxcxwcx\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 30 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250628_235454-khxcxwcx/logs\u001b[0m\n"]}],"execution_count":24},{"id":"13d3235e","cell_type":"markdown","source":"### Uncertainty Estimation for Sample Efficient RPF Bootstrap DQN","metadata":{"papermill":{"duration":0.043619,"end_time":"2025-06-29T01:21:55.744213","exception":false,"start_time":"2025-06-29T01:21:55.700594","status":"completed"},"tags":[]}},{"id":"5dab4df0","cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nwandb_config = {\n    \"project\": PROJECT_NAME,\n    \"name\": \"uncertainty_estimation\",\n    \"save_code\": SAVE_CODE,\n    \"tags\": [\"dqn\", \"ue_bootstrap\"],\n}\n\nwandb_config[\"config\"] = {} if TA else {**ue_bootstrap_dqn_config, **base_run_config, \"machine\": get_machine()}\n\nif DEBUG:\n    wandb_run = None\nelse:\n    wandb_run = wandb.init(**wandb_config)\n\nue_bootstrap_dqn_agent = UEBootstrapDQNAgent(wandb_run=wandb_run, **ue_bootstrap_dqn_config)","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:13:08.305435Z","iopub.execute_input":"2025-06-29T07:13:08.306282Z","iopub.status.idle":"2025-06-29T07:13:28.729611Z","shell.execute_reply.started":"2025-06-29T07:13:08.306252Z","shell.execute_reply":"2025-06-29T07:13:28.729065Z"},"papermill":{"duration":0.900559,"end_time":"2025-06-29T01:21:56.686332","exception":true,"start_time":"2025-06-29T01:21:55.785773","status":"failed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielparnian\u001b[0m (\u001b[33mdanialpa\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250629_071314-sc6xq305</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW/runs/sc6xq305' target=\"_blank\">uncertainty_estimation</a></strong> to <a href='https://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW' target=\"_blank\">https://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW/runs/sc6xq305' target=\"_blank\">https://wandb.ai/danialpa/Danial-Parnian-DQN-EXPLORE-HW/runs/sc6xq305</a>"},"metadata":{}}],"execution_count":19},{"id":"394cbe7c","cell_type":"code","source":"# DON'T CHANGE THIS BLOCK\nue_bootstrap_dqn_agent.train(**base_run_config)\nwandb_run.finish()","metadata":{"execution":{"iopub.status.busy":"2025-06-29T07:13:38.503754Z","iopub.execute_input":"2025-06-29T07:13:38.504218Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\nerror: XDG_RUNTIME_DIR not set in the environment.\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n/tmp/ipykernel_35/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/2900081785.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/usr/local/lib/python3.11/dist-packages/bootstrapdqn/base_agent.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  torch.tensor(state, device=self.device),\n/tmp/ipykernel_35/2900081785.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device)\n/tmp/ipykernel_35/1916844783.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  state_tensor = torch.tensor(state, dtype=torch.float32, device=self.device)\n/tmp/ipykernel_35/1916844783.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device)\n","output_type":"stream"}],"execution_count":null}]}